import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
from sklearn.metrics import auc
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import normalize
from copy import deepcopy

# load and summarize the dataset
from pandas import read_csv
from collections import Counter
# define the dataset location
filename = 'adult.csv'
# load the csv file as a data frame
df = read_csv(filename, header=None, na_values='?')
# drop rows with missing
df = df.dropna()
# summarize the shape of the dataset
print(df.shape)
# summarize the class distribution
target = df.values[:,-1]
counter = Counter(target)
for k,v in counter.items():
	per = v / len(target) * 100
	print('Class=%s, Count=%d, Percentage=%.3f%%' % (k, v, per))

# select columns with numerical data types
num_ix = df.select_dtypes(include=['int64', 'float64']).columns
# select a subset of the dataframe with the chosen columns
subset = df[num_ix]
# create a histogram plot of each numeric variable
# subset.hist()
plt.show()

# fit a model and make predictions for the on the adult dataset
from pandas import read_csv
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from imblearn.pipeline import Pipeline

# load the dataset
def load_dataset(full_path):
  # load the dataset as a numpy array
  dataframe = read_csv(full_path, header=None, na_values='?')
  # drop rows with missing
  dataframe = dataframe.dropna()
  # split into inputs and outputs
  last_ix = len(dataframe.columns) - 1
  X, y = dataframe.drop(last_ix, axis=1), dataframe[last_ix]
  # select categorical and numerical features
  cat_ix = X.select_dtypes(include=['object', 'bool']).columns
  num_ix = X.select_dtypes(include=['int64', 'float64']).columns
  # label encode the target variable to have the classes 0 and 1
  y = LabelEncoder().fit_transform(y)
  return X.values, y, cat_ix, num_ix

# define the location of the dataset
full_path = 'adult.csv'
# load the dataset
X, y, cat_ix, num_ix = load_dataset(full_path)
# define model to evaluate
model = GradientBoostingClassifier(n_estimators=100)
model2 = SVC()

# one hot encode categorical, normalize numerical
ct = ColumnTransformer([('c',OneHotEncoder(handle_unknown = 'ignore'),cat_ix), ('n',MinMaxScaler(),num_ix)])
# define the pipeline
pipeline = Pipeline(steps=[('t',ct), ('m',model)])
pipeline2 = Pipeline(steps=[('t',ct), ('m',model2)])
# split test and train data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)
# fit the model
trained_model = pipeline.fit(X_train, y_train)
trained_model2 = pipeline2.fit(X_train, y_train)